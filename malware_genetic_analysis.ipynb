{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of a genetic algorithm on a Neural Network using Tensorflow - Malware detection with Machine Learning\n",
    "The goal of this notebook is to achieve a **classification** in order to **detect Android malwares**. The process will be to feed forward an **Artificial Neural Network** with a pre-processed and clean dataset of Java Bytecode, and predict if it is **benign or not**. \n",
    "\n",
    "Then, we apply a **genetic algorithm** with the aim of getting the most optimized parameters for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:20:44.376343Z",
     "start_time": "2018-03-01T12:20:44.331722Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset -f "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T09:27:43.704254Z",
     "start_time": "2018-02-13T09:27:43.672995Z"
    }
   },
   "source": [
    "> **Tensorflow** will be used for building and training the neural network,  \n",
    "> **Pandas** for the first data processing and visualization,   \n",
    "> **Matplotlib** (with **Seaborn backend**) will be used to plot the results of the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:20:57.290209Z",
     "start_time": "2018-03-01T12:20:44.379853Z"
    }
   },
   "outputs": [],
   "source": [
    "import genev # genetic algorithm\n",
    "from genev import Individual, Evolution\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import timedelta\n",
    "from numpy import linalg as LA\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "sns.set()   # Set seaborn as backend\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Hide messy TensorFlow warnings\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\" # Enhance matplotlib on hdpi displays\n",
    "%autonotify --after 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T09:17:00.635192Z",
     "start_time": "2018-02-13T09:17:00.603937Z"
    }
   },
   "source": [
    "## Import the dataset\n",
    "The dataset contains supposedly contains **5541** Android Malwares and **2166** benign applications. The input/output shape for each item is **5971/2** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:20:57.303233Z",
     "start_time": "2018-03-01T12:20:57.295215Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"./android-features.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:47.564542Z",
     "start_time": "2018-03-01T12:20:57.308248Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"95bf5493-0ab1-4378-bdd4-7167fc6b08da\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"95bf5493-0ab1-4378-bdd4-7167fc6b08da\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell Execution Has Finished!!\", \"autonotify_after\": \"30\", \"autonotify_output\": false};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 0\n",
    "_samples = None\n",
    "_input_size, _output_size = None, None \n",
    "_raw_inputs, _raw_outputs = [], []\n",
    "\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # Parse string data to float\n",
    "        data = [float(i) for i in line.split()]\n",
    "        \n",
    "        # Read header\n",
    "        if _samples is None:\n",
    "            _samples = int(data[0])\n",
    "            _input_size = int(data[1])\n",
    "            _output_size = int(data[2])\n",
    "            continue\n",
    "            \n",
    "        if count % 2 == 0:\n",
    "            _raw_inputs.append(data)\n",
    "        else:\n",
    "            _raw_outputs.append(data)\n",
    "        \n",
    "_raw_inputs = np.asarray(_raw_inputs)\n",
    "_raw_outputs = np.asarray(_raw_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we correctly have the right shapes of data. The shapes of the array will confirm us if we loaded correctly all data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:47.595625Z",
     "start_time": "2018-03-01T12:21:47.571061Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_samples 7707\n",
      "_input_size 5971\n",
      "_output_size 2\n",
      "_raw_inputs.shape (7707, 5971)\n",
      "_raw_outputs.shape (7707, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"_samples\", _samples)\n",
    "print(\"_input_size\", _input_size)\n",
    "print(\"_output_size\", _output_size)\n",
    "print(\"_raw_inputs.shape\", _raw_inputs.shape)\n",
    "print(\"_raw_outputs.shape\", _raw_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the data\n",
    "Our objective is to get knowledge about the data that we manipulate and, for example, verify that the inputs are **normalized** as well as the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:47.729480Z",
     "start_time": "2018-03-01T12:21:47.606655Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5961</th>\n",
       "      <th>5962</th>\n",
       "      <th>5963</th>\n",
       "      <th>5964</th>\n",
       "      <th>5965</th>\n",
       "      <th>5966</th>\n",
       "      <th>5967</th>\n",
       "      <th>5968</th>\n",
       "      <th>5969</th>\n",
       "      <th>5970</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029498</td>\n",
       "      <td>0.061378</td>\n",
       "      <td>0.033071</td>\n",
       "      <td>0.036460</td>\n",
       "      <td>0.050385</td>\n",
       "      <td>0.106724</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>0.135672</td>\n",
       "      <td>0.058721</td>\n",
       "      <td>0.037651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025469</td>\n",
       "      <td>0.083780</td>\n",
       "      <td>0.031166</td>\n",
       "      <td>0.036528</td>\n",
       "      <td>0.061662</td>\n",
       "      <td>0.105228</td>\n",
       "      <td>0.054960</td>\n",
       "      <td>0.171917</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.045576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031334</td>\n",
       "      <td>0.047353</td>\n",
       "      <td>0.035140</td>\n",
       "      <td>0.029078</td>\n",
       "      <td>0.022517</td>\n",
       "      <td>0.110379</td>\n",
       "      <td>0.039792</td>\n",
       "      <td>0.138919</td>\n",
       "      <td>0.041612</td>\n",
       "      <td>0.026272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035820</td>\n",
       "      <td>0.081835</td>\n",
       "      <td>0.022787</td>\n",
       "      <td>0.031889</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>0.092903</td>\n",
       "      <td>0.033469</td>\n",
       "      <td>0.100370</td>\n",
       "      <td>0.043728</td>\n",
       "      <td>0.023393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030828</td>\n",
       "      <td>0.046942</td>\n",
       "      <td>0.037359</td>\n",
       "      <td>0.027488</td>\n",
       "      <td>0.022576</td>\n",
       "      <td>0.104237</td>\n",
       "      <td>0.042742</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.039941</td>\n",
       "      <td>0.025916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5971 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1         2     3         4         5     6         7     \\\n",
       "0  0.000000  0.00000  0.000275   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "1  0.000000  0.00000  0.000000   0.0  0.000335  0.000000   0.0  0.000000   \n",
       "2  0.000013  0.00009  0.000000   0.0  0.000013  0.000013   0.0  0.000013   \n",
       "3  0.000018  0.00000  0.000055   0.0  0.000000  0.000009   0.0  0.000009   \n",
       "4  0.000011  0.00008  0.000023   0.0  0.000011  0.000011   0.0  0.000011   \n",
       "\n",
       "       8         9       ...         5961      5962      5963      5964  \\\n",
       "0  0.000000  0.000000    ...     0.029498  0.061378  0.033071  0.036460   \n",
       "1  0.000000  0.000000    ...     0.025469  0.083780  0.031166  0.036528   \n",
       "2  0.000013  0.000000    ...     0.031334  0.047353  0.035140  0.029078   \n",
       "3  0.000018  0.000046    ...     0.035820  0.081835  0.022787  0.031889   \n",
       "4  0.000023  0.000000    ...     0.030828  0.046942  0.037359  0.027488   \n",
       "\n",
       "       5965      5966      5967      5968      5969      5970  \n",
       "0  0.050385  0.106724  0.041774  0.135672  0.058721  0.037651  \n",
       "1  0.061662  0.105228  0.054960  0.171917  0.057306  0.045576  \n",
       "2  0.022517  0.110379  0.039792  0.138919  0.041612  0.026272  \n",
       "3  0.044527  0.092903  0.033469  0.100370  0.043728  0.023393  \n",
       "4  0.022576  0.104237  0.042742  0.133000  0.039941  0.025916  \n",
       "\n",
       "[5 rows x 5971 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(_raw_inputs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:47.764072Z",
     "start_time": "2018-03-01T12:21:47.735497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1\n",
       "0  0.95  0.05\n",
       "1  0.95  0.05\n",
       "2  0.95  0.05\n",
       "3  0.95  0.05\n",
       "4  0.95  0.05"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(_raw_outputs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation datasets creation\n",
    "As we can see above, the data is not equally divided in the dataset: it is sorted by class (malware first, benign last).   \n",
    "Thus, we can start by **shuffling the dataset**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:48.196222Z",
     "start_time": "2018-03-01T12:21:47.772598Z"
    }
   },
   "outputs": [],
   "source": [
    "X_all, y_all = shuffle(_raw_inputs, _raw_outputs, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance purpose, we will take only **10% of the dataset** in order to speedup the overall  process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:48.224798Z",
     "start_time": "2018-03-01T12:21:48.206752Z"
    }
   },
   "outputs": [],
   "source": [
    "part = 0.1 # take a small part\n",
    "size = X_all.shape[0]\n",
    "\n",
    "X_data = X_all[: int(size * part)]\n",
    "y_data = y_all[: int(size * part)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to split it 3 parts with 3 different purpose: \n",
    "- The **training dataset** - 60% (*gain knowledge*)\n",
    "- The **validation dataset** - 20% (*validate the ability of generalizing*)\n",
    "- The **test dataset** - 20% (*test the accuracy*)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:48.281951Z",
     "start_time": "2018-03-01T12:21:48.229310Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data.shape (770, 5971) \t y_data.shape (770, 2)\n",
      "X_train.shape (462, 5971) \t y_train.shape (462, 2)\n",
      "X_val.shape (154, 5971) \t y_val.shape (154, 2)\n",
      "X_test.shape (154, 5971) \t y_test.shape (154, 2)\n"
     ]
    }
   ],
   "source": [
    "validation_part = 0.20\n",
    "test_part = 0.20\n",
    "train_part = 1 - validation_part - test_part\n",
    "\n",
    "size = X_data.shape[0]\n",
    "\n",
    "# Create cross-validation datasets\n",
    "X_train = X_data[: int(size * train_part)]\n",
    "y_train = y_data[: int(size * train_part)]\n",
    "\n",
    "X_val = X_data[X_train.shape[0]: X_train.shape[0] + int(size * validation_part)]\n",
    "y_val = y_data[y_train.shape[0]: y_train.shape[0] + int(size * validation_part)]\n",
    "\n",
    "X_test = X_data[-int(size * test_part):]\n",
    "y_test = y_data[-int(size * test_part):]\n",
    "    \n",
    "print(\"X_data.shape\", X_data.shape, \"\\t\", \"y_data.shape\", y_data.shape)\n",
    "print(\"X_train.shape\", X_train.shape, \"\\t\", \"y_train.shape\", y_train.shape)\n",
    "print(\"X_val.shape\", X_val.shape, \"\\t\", \"y_val.shape\", y_val.shape)\n",
    "print(\"X_test.shape\", X_test.shape, \"\\t\", \"y_test.shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:22:03.035244Z",
     "start_time": "2018-02-12T14:22:03.031232Z"
    }
   },
   "source": [
    "### Analysis of the malware/benign distribution\n",
    "Now that we have shuffled our data and splitted our data, we need to check that it is correctly distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:48.895585Z",
     "start_time": "2018-03-01T12:21:48.287968Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0.95, 0.05)</th>\n",
       "      <th>(0.05, 0.95)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y_data</th>\n",
       "      <td>542</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_train</th>\n",
       "      <td>324</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_val</th>\n",
       "      <td>111</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_test</th>\n",
       "      <td>107</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         (0.95, 0.05)  (0.05, 0.95)\n",
       "y_data            542           228\n",
       "y_train           324           138\n",
       "y_val             111            43\n",
       "y_test            107            47"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13febd5ea20>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 263,
       "width": 596
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def frame(dataset, label):\n",
    "    \n",
    "    df = pd.DataFrame(dataset)\n",
    "    columns = [() for _ in range(df.shape[1])]\n",
    "    values = [None for _ in range(df.shape[1])]\n",
    "\n",
    "    for n in df:\n",
    "        for i, item in enumerate(df[n].value_counts().items()):\n",
    "            columns[i] += (item[0],)\n",
    "            values[i] = item[1]\n",
    "\n",
    "    df = pd.DataFrame([values], index=[label], columns=columns)\n",
    "    return df\n",
    "    \n",
    "df1 = frame(y_data, \"y_data\")\n",
    "df2 = frame(y_train, \"y_train\")\n",
    "df3 = frame(y_val, \"y_val\")\n",
    "df4 = frame(y_test, \"y_test\")\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "display(df)\n",
    "\n",
    "hist = df.plot.bar(rot=0, figsize=(10, 4))\n",
    "hist.set_title(\"Distribution in of malware/benign\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T13:05:15.232133Z",
     "start_time": "2018-02-02T13:05:15.226638Z"
    }
   },
   "source": [
    "Thanks to this histogram, we are now sure that each set is representative of our global data.\n",
    "\n",
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a style=\"float:right\" href=\"https://en.wikipedia.org/wiki/Sensitivity_and_specificity#/media/File:Sensitivity_and_specificity.svg\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg\" width=\"250px\">\"Sensitivity and specificity\", from Wikipedia</a>\n",
    "As well as we do a classification, the purpose of the test dataset is to ensure that the classficiation is correct.  \n",
    "The following is implemented under `Model.test(, X, Y)`\n",
    "\n",
    "> **True positive** (TP): correctly identified   \n",
    "    *We predicted \"malware\" and the true class is \"malware\"*  \n",
    "\n",
    "> **False positive** (FP): incorrectly identified   \n",
    "    *We predicted \"not malware\" and the true class is \"not malware\"*\n",
    "        \n",
    "> **True negative** (TN): correctly rejected    \n",
    "    *We predicted \"malware\" and the true class is \"not malware\"*\n",
    "\n",
    "> **False negative** (FN): incorrectly rejected     \n",
    "    *We predicted \"not malware\" and the true class is \"malware\"*\n",
    "    \n",
    "The following measures can be calculated:\n",
    "* **Accuracy**\n",
    "* **Misclassification Error** (or Error Rate)\n",
    "* **Receiver Operating Characteristic** (ROC)\n",
    "\n",
    "More info on http://mlwiki.org/index.php/Evaluation_of_Binary_Classifiers#Accuracy_and_Error_Rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:48.928674Z",
     "start_time": "2018-03-01T12:21:48.917141Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_malware(value : tuple):\n",
    "    return True if value[0] > value[1] else False # ex: 0.91 > 0.12 means it is categorized as a malware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T12:46:03.095184Z",
     "start_time": "2018-02-13T12:46:03.048187Z"
    }
   },
   "source": [
    "We register the model as a class in order to produce as many copies of this model as we want for soon generating each population of a our genetic algorithm.   \n",
    "Here are most important methods:\n",
    "* `__init__()` take all hyperparameters that will be dynamically modified by the genetic algorithm as arguments\n",
    "* `build()` creates the Tensorflow graph given the model's hyperparameters\n",
    "* `train_on_batch()` optimizes the internal weights of the model given the data and the `batch_size` (it can be 1)\n",
    "* `validate_on_batch()` returns metrics of the current model tested on the given data and the batch size\n",
    "* `fit()` calls `train_on_batch()` on the whole training set and validate its performance on the validation set each `epochs_between_reports`\n",
    "* `test()` return metrics of the current model tested on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:53.170006Z",
     "start_time": "2018-03-01T12:21:48.943712Z"
    },
    "code_folding": [
     2,
     25,
     67,
     98,
     103,
     162,
     199,
     218,
     246
    ]
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "\n",
    "    def __init__(self, learning_rate=0.01, momentum=0.9, lr_decay=0.0, hidden_layers=1, hidden_size=1, activation=\"linear\"):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.lr_decay = lr_decay\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.activation = activation\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.validation_losses = []\n",
    "        self.metrics = []\n",
    "        self.times = []\n",
    "        self.training_time = None\n",
    "\n",
    "        self.status = \"live\" # other values: [\"early_stopped\", \"gone_to_infinite\"]\n",
    "        self.aborted = False\n",
    "        self.epochs_between_reports = 10\n",
    "        self.desired_error = 0.001\n",
    "        \n",
    "        # Initialize session\n",
    "        self.build(X_data.shape[1], y_data.shape[1])\n",
    "        \n",
    "    def build(self, input_shape, output_shape):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.graph = tf.Graph()\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            with tf.variable_scope(\"Core_layers\"):\n",
    "\n",
    "                # Pick between available activations\n",
    "                activations = {\"linear\": None, \"sigmoid\": tf.nn.sigmoid, \"tanh\": tf.nn.tanh, \"relu\": tf.nn.relu}\n",
    "                activation = activations[self.activation]\n",
    "                \n",
    "                # Input dense layer\n",
    "                x = tf.placeholder(tf.float32, shape=(None, input_shape))\n",
    "                y = tf.placeholder(tf.float32, shape=(None, output_shape))\n",
    "                layers = [tf.layers.dense(inputs=x, units=self.hidden_size, activation=activation)]\n",
    "\n",
    "                # Hidden layers\n",
    "                for i in range(self.hidden_layers):\n",
    "                    layers.append(tf.layers.dense(inputs=layers[-1], units=self.hidden_size, activation=activation))\n",
    "\n",
    "                # Output dense layer\n",
    "                output = tf.layers.dense(inputs=layers[-1], units=output_shape, activation=activation)\n",
    "\n",
    "                # Loss function (MSE)\n",
    "                loss = tf.losses.mean_squared_error(labels=y, predictions=output)\n",
    "\n",
    "                # Optimize the loss minimization\n",
    "                optimizer = tf.train.RMSPropOptimizer(self.learning_rate, momentum=self.momentum, decay=self.lr_decay)\n",
    "                #optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "                train_op = optimizer.minimize(loss)\n",
    "\n",
    "                # Add variables as params to be accessible in the whole object\n",
    "                self.x = x\n",
    "                self.y = y\n",
    "                self.output = output\n",
    "                self.loss = loss\n",
    "                self.train_op = train_op\n",
    "                self.sess = tf.Session()\n",
    "\n",
    "                assert loss.graph is self.graph\n",
    "            \n",
    "    def train_on_batch(self, X, Y, batch_size=None, train=True):\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            \n",
    "            # Get variables from the building\n",
    "            x, y = self.x, self.y\n",
    "            loss, train_op = self.loss, self.train_op\n",
    "            \n",
    "            # Compute dataset windows corresponding to the batch size\n",
    "            dataset_size = X.shape[0]\n",
    "            batch_size = dataset_size if batch_size is None else batch_size\n",
    "            windows = zip(range(0, dataset_size, batch_size), range(batch_size, dataset_size+1, batch_size))\n",
    "\n",
    "            start_time = time.time()\n",
    "            losses = []\n",
    "\n",
    "            # Fetch by window of dataset[start:end]\n",
    "            for start, end in windows:\n",
    "                \n",
    "                loss_t = self.sess.run([loss, train_op] if train is True else [loss], {x: X, y: Y})\n",
    "                \n",
    "                if not np.isfinite(loss_t[0]):\n",
    "                    self.status = \"gone_to_infinite\"\n",
    "                    self.aborted = True\n",
    "                    break\n",
    "                    \n",
    "                losses.append(loss_t[0])\n",
    "\n",
    "            # Return the mean loss and elapsed time for this epoch    \n",
    "            return np.mean(losses), time.time() - start_time     \n",
    "        \n",
    "    def validate_on_batch(self, X, Y, batch_size=1):\n",
    "        \n",
    "        # Call train function but with train=False option\n",
    "        return self.train_on_batch(X, Y, batch_size, train=False)\n",
    "    \n",
    "    def fit(self, X_train, Y_train, X_validation, Y_validation, X_test, Y_test, epochs, batch_size=None, early_stopping=True, verbose=False):\n",
    "\n",
    "        if epochs % self.epochs_between_reports != 0:\n",
    "            print(\"Warning: it is recommended to set a number of `epochs` divisible by the `epochs_between_reports`\")\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "\n",
    "            train_losses = []\n",
    "            validation_losses = []\n",
    "            metrics = []\n",
    "            times = []\n",
    "            \n",
    "            # Initialize weights and biais\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            # Fetch the dataset through epochs\n",
    "            for i in range(1, epochs+1):\n",
    "\n",
    "                # Train & save metrics\n",
    "                loss, t = self.train_on_batch(X_train, Y_train, batch_size)\n",
    "                train_losses.append(loss)\n",
    "                times.append(t)\n",
    "                \n",
    "                if self.aborted:\n",
    "                    break\n",
    "\n",
    "                # Validate, test and fire early stopping if necessary\n",
    "                if i % self.epochs_between_reports == 0:\n",
    "\n",
    "                    # Validate\n",
    "                    val_loss, t = self.validate_on_batch(X_validation, Y_validation, batch_size)\n",
    "                    validation_losses.append(val_loss)\n",
    "                    \n",
    "                    # Test and save metrics\n",
    "                    test_metrics = self.test(X_test, Y_test)\n",
    "                    acc = test_metrics[\"accuracy\"]\n",
    "                    metrics.append(test_metrics)\n",
    "                    \n",
    "                    # Early Stopping\n",
    "                    if early_stopping:\n",
    "                        if len(validation_losses) > 2 and val_loss > validation_losses[-2]:\n",
    "                            self.status = \"early_stopped: val_loss gone up\"\n",
    "                            self.aborted = True\n",
    "                        if val_loss < self.desired_error:\n",
    "                            self.status = \"early_stopped: desired error reached\"\n",
    "                            sefl.aborted = True\n",
    "                        \n",
    "                    if verbose is True:\n",
    "                        print(\"epoch #{0:}\\tloss: {1:.4f} / {2:.4f}\\tacc: {3:.2f}\".format(i, loss, val_loss, acc))\n",
    "                    \n",
    "            # Save the metrics\n",
    "            self.train_losses = np.asarray(train_losses)\n",
    "            self.validation_losses = np.asarray(validation_losses)\n",
    "            self.metrics = np.asarray(metrics)\n",
    "            self.times = np.asarray(times)\n",
    "            self.training_time = np.sum(times)\n",
    "\n",
    "            return self.train_losses, self.validation_losses, self.metrics, self.times\n",
    "    \n",
    "    def test(self, X, Y):\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            classes = [(0.95, 0.05), (0.05, 0.95)]\n",
    "        \n",
    "            # Predict\n",
    "            predicted = self.sess.run([self.output], {self.x: X})\n",
    "            predicted = np.asarray(predicted[0])\n",
    "            expected = Y\n",
    "\n",
    "            # Establish the count of TP, TN, FP, FN\n",
    "            TP, TN, FP, FN = 0, 0, 0, 0\n",
    "            n_malwares = 0\n",
    "            for pred, exp in zip(predicted, expected):\n",
    "                n_malwares += 1 if is_malware(exp) else 0\n",
    "                TP += 1 if is_malware(pred) and is_malware(exp) else 0\n",
    "                TN += 1 if not is_malware(pred) and not is_malware(exp) else 0\n",
    "                FP += 1 if is_malware(pred) and not is_malware(exp) else 0\n",
    "                FN += 1 if not is_malware(pred) and is_malware(exp) else 0\n",
    "                \n",
    "            # Compute the rates\n",
    "            accuracy = (TP + TN) / len(expected)\n",
    "            error = 1 - accuracy\n",
    "            TPR = TP / (TP + FN)\n",
    "            FPR = FP / (FP + TN)\n",
    "                \n",
    "            return {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"error\": error,\n",
    "                \"true_positive\": TP,\n",
    "                \"true_negative\": TN,\n",
    "                \"true_positive_rate\": TPR,\n",
    "                \"false_positive\": FP,\n",
    "                \"false_negative\": FN,\n",
    "                \"false_positive_rate\": FPR\n",
    "            }\n",
    "            \n",
    "    def display_losses(self, figsize=(12, 4)):\n",
    "        \n",
    "        train, val = np.asarray(self.train_losses), np.asarray(self.validation_losses)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "        x_axis = np.arange(len(val))/float(len(val)-1)*(len(train)-1)\n",
    "\n",
    "        for ax in (ax1, ax2):\n",
    "            data = [train, val] if ax == ax1 else [np.log(train), np.log(val)]\n",
    "            ax.plot(data[0], label=\"train\")\n",
    "            ax.plot(x_axis, data[1], label=\"validation\")\n",
    "            ax.set_xlabel(\"epoch\")\n",
    "            ax.set_ylabel(\"loss\")\n",
    "\n",
    "        plt.suptitle(\"model losses after {}s\".format(str(timedelta(seconds=self.training_time))), fontsize=16, y=1.10)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def display_metrics(self, figsize=(8, 4)):\n",
    "        \n",
    "        acc = np.asarray([m[\"accuracy\"] for m in self.metrics])\n",
    "        \n",
    "        # We also add the points (0, 0) and (1, 1)\n",
    "        fpr = np.asarray([0, 1] + [m[\"false_positive_rate\"] for m in self.metrics])\n",
    "        tpr = np.asarray([0, 1] + [m[\"true_positive_rate\"] for m in self.metrics])\n",
    "        \n",
    "        # Sort fpr\n",
    "        p = fpr.argsort()\n",
    "        fpr, tpr = fpr[p], tpr[p]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize, sharey=True)\n",
    "        ax1.plot(acc, label=\"accuracy\", color=\"orange\")\n",
    "        ax1.set_xlabel(\"epoch\")\n",
    "        ax1.set_ylabel(\"accuracy\")\n",
    "        \n",
    "        ax2.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "        ax2.plot(fpr, tpr, \"-r\", zorder=1)\n",
    "        ax2.scatter(fpr, tpr, marker=\",\", color=(0.8, 0, 0), s=10, zorder=2)\n",
    "        ax2.set_xlabel(\"False Positive Rate\")\n",
    "        ax2.set_ylabel(\"True Positive Rate\")\n",
    "        \n",
    "        plt.suptitle(\"metrics after {}s\".format(str(timedelta(seconds=self.training_time))), fontsize=16, y=1.10)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def free(self):\n",
    "        with self.graph.as_default():\n",
    "            self.sess.close()    \n",
    "        \n",
    "    def __delete__(self):\n",
    "        self.free()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training part\n",
    "At this point, we can create a model given the right parameters and test its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:53.255728Z",
     "start_time": "2018-03-01T12:21:53.182533Z"
    }
   },
   "outputs": [],
   "source": [
    "# Found w/out the correction,\n",
    "# the best for now\n",
    "# params= {'hidden_layers': 0,\n",
    "#         'hidden_size': 2,\n",
    "#         'learning_rate': 0.013706071546456982,\n",
    "#         'lr_decay': 0.011089306018502533,\n",
    "#         'momentum': 0.5005674938587366}\n",
    "\n",
    "# Found w/ correction of hidden_size in the first layer\n",
    "# params= {'hidden_layers': 2,\n",
    "#          'hidden_size': 6,\n",
    "#          'learning_rate': 0.004958809888366004,\n",
    "#          'lr_decay': 0.1078463266290153,\n",
    "#          'momentum': 0.4032715476772463}\n",
    "# params= {'hidden_layers': 2,\n",
    "#          'hidden_size': 26,\n",
    "#          'learning_rate': 0.0033873562586149166,\n",
    "#          'lr_decay': 1.1711835015804154e-06,\n",
    "#          'momentum': 0.25234057722690856}\n",
    "\n",
    "# params = {'activation': 'sigmoid',\n",
    "#          'hidden_layers': 1,\n",
    "#          'hidden_size': 0,\n",
    "#          'learning_rate': 0.17429191970420493,\n",
    "#          'lr_decay': 0.09907799396487428,\n",
    "#          'momentum': 0.1889544477838457}\n",
    "\n",
    "params = {'activation': 'tanh',\n",
    " 'hidden_layers': 3,\n",
    " 'hidden_size': 9,\n",
    " 'learning_rate': 0.0028803199879704213,\n",
    " 'lr_decay': 0.06169868522111648,\n",
    " 'momentum': 0.4612098539149855}\n",
    "\n",
    "# params = {'learning_rate': 0.0004192211223496255,\n",
    "#  'hidden_layers': 2,\n",
    "#  'lr_decay': 0.00030996529008363977,\n",
    "#  'hidden_size': 18,\n",
    "#  'activation': 'tanh',\n",
    "#  'momentum': 0.9207677937939145}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:21:54.054770Z",
     "start_time": "2018-03-01T12:21:53.260741Z"
    }
   },
   "outputs": [],
   "source": [
    "m1 = Model(**params)\n",
    "m1.epochs_between_reports = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T11:16:10.812637Z",
     "start_time": "2018-02-12T11:16:10.781358Z"
    }
   },
   "source": [
    "Train the model. For a more precise result, `batch_size=1` is better. For a quick result, `batch_size=None` will proceed the whole passed data as a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.560208Z",
     "start_time": "2018-03-01T12:21:54.060779Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #10\tloss: 0.1626 / 0.1531\tacc: 0.69\n",
      "epoch #20\tloss: 0.1188 / 0.1160\tacc: 0.77\n",
      "epoch #30\tloss: 0.0895 / 0.0864\tacc: 0.83\n",
      "epoch #40\tloss: 0.0766 / 0.0761\tacc: 0.89\n",
      "epoch #50\tloss: 0.0690 / 0.0713\tacc: 0.90\n",
      "epoch #60\tloss: 0.0636 / 0.0681\tacc: 0.92\n",
      "epoch #70\tloss: 0.0593 / 0.0656\tacc: 0.93\n",
      "epoch #80\tloss: 0.0558 / 0.0634\tacc: 0.92\n",
      "epoch #90\tloss: 0.0527 / 0.0617\tacc: 0.93\n",
      "epoch #100\tloss: 0.0501 / 0.0601\tacc: 0.93\n",
      "epoch #110\tloss: 0.0478 / 0.0587\tacc: 0.92\n",
      "epoch #120\tloss: 0.0458 / 0.0575\tacc: 0.92\n",
      "epoch #130\tloss: 0.0441 / 0.0564\tacc: 0.94\n",
      "epoch #140\tloss: 0.0425 / 0.0553\tacc: 0.94\n",
      "epoch #150\tloss: 0.0410 / 0.0544\tacc: 0.94\n",
      "epoch #160\tloss: 0.0397 / 0.0536\tacc: 0.94\n",
      "epoch #170\tloss: 0.0385 / 0.0528\tacc: 0.94\n",
      "epoch #180\tloss: 0.0373 / 0.0520\tacc: 0.94\n",
      "epoch #190\tloss: 0.0362 / 0.0513\tacc: 0.94\n",
      "epoch #200\tloss: 0.0352 / 0.0507\tacc: 0.94\n",
      "epoch #210\tloss: 0.0343 / 0.0501\tacc: 0.94\n",
      "epoch #220\tloss: 0.0334 / 0.0495\tacc: 0.94\n",
      "epoch #230\tloss: 0.0326 / 0.0490\tacc: 0.95\n",
      "epoch #240\tloss: 0.0318 / 0.0484\tacc: 0.95\n",
      "epoch #250\tloss: 0.0311 / 0.0478\tacc: 0.95\n",
      "epoch #260\tloss: 0.0303 / 0.0472\tacc: 0.96\n",
      "epoch #270\tloss: 0.0296 / 0.0466\tacc: 0.96\n",
      "epoch #280\tloss: 0.0289 / 0.0460\tacc: 0.96\n",
      "epoch #290\tloss: 0.0282 / 0.0454\tacc: 0.96\n",
      "epoch #300\tloss: 0.0275 / 0.0448\tacc: 0.96\n",
      "epoch #310\tloss: 0.0267 / 0.0441\tacc: 0.96\n",
      "epoch #320\tloss: 0.0260 / 0.0434\tacc: 0.96\n",
      "epoch #330\tloss: 0.0253 / 0.0427\tacc: 0.96\n",
      "epoch #340\tloss: 0.0246 / 0.0420\tacc: 0.96\n",
      "epoch #350\tloss: 0.0239 / 0.0413\tacc: 0.96\n",
      "epoch #360\tloss: 0.0232 / 0.0407\tacc: 0.96\n",
      "epoch #370\tloss: 0.0225 / 0.0401\tacc: 0.96\n",
      "epoch #380\tloss: 0.0218 / 0.0394\tacc: 0.96\n",
      "epoch #390\tloss: 0.0212 / 0.0388\tacc: 0.96\n",
      "epoch #400\tloss: 0.0205 / 0.0381\tacc: 0.96\n",
      "epoch #410\tloss: 0.0198 / 0.0374\tacc: 0.96\n",
      "epoch #420\tloss: 0.0191 / 0.0367\tacc: 0.96\n",
      "epoch #430\tloss: 0.0184 / 0.0359\tacc: 0.96\n",
      "epoch #440\tloss: 0.0177 / 0.0352\tacc: 0.96\n",
      "epoch #450\tloss: 0.0171 / 0.0345\tacc: 0.96\n",
      "epoch #460\tloss: 0.0164 / 0.0338\tacc: 0.96\n",
      "epoch #470\tloss: 0.0157 / 0.0332\tacc: 0.96\n",
      "epoch #480\tloss: 0.0151 / 0.0325\tacc: 0.96\n",
      "epoch #490\tloss: 0.0144 / 0.0320\tacc: 0.96\n",
      "epoch #500\tloss: 0.0138 / 0.0314\tacc: 0.96\n",
      "epoch #510\tloss: 0.0132 / 0.0310\tacc: 0.96\n",
      "epoch #520\tloss: 0.0127 / 0.0305\tacc: 0.96\n",
      "epoch #530\tloss: 0.0121 / 0.0301\tacc: 0.95\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b9de8d0e1f16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-aeb924796f36>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, Y_train, X_validation, Y_validation, X_test, Y_test, epochs, batch_size, early_stopping, verbose)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;31m# Train & save metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m                 \u001b[0mtrain_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-aeb924796f36>\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, X, Y, batch_size, train)\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwindows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mloss_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtrain\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_t\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1095\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32mc:\\python3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, val_loss, metrics, t = m1.fit(X_train, y_train, X_val, y_val, X_test, y_test, epochs=1000, batch_size=None, early_stopping=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.564221Z",
     "start_time": "2018-03-01T12:20:44.473Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m1.display_losses()\n",
    "m1.display_metrics()\n",
    "m1.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T10:54:51.698474Z",
     "start_time": "2018-02-13T10:54:51.682848Z"
    }
   },
   "source": [
    "Get the accuracy from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.569232Z",
     "start_time": "2018-03-01T12:20:44.483Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m1.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**/!\\ Important:** do not forget to free the session, if not the memory will be huge in a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.572240Z",
     "start_time": "2018-03-01T12:20:44.492Z"
    }
   },
   "outputs": [],
   "source": [
    "#del m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T15:34:10.152676Z",
     "start_time": "2018-02-12T15:29:17.975Z"
    }
   },
   "source": [
    "## Genetic algorithm configuration\n",
    "### Configure the hyperparameters that can be changed\n",
    "Each parameters should be associated with a tuple describing the expected value like `(value_type, picking_function)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.574747Z",
     "start_time": "2018-03-01T12:20:44.499Z"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"learning_rate\": (float, lambda: 10 ** np.random.uniform(-4, 0)),\n",
    "    \"momentum\": (float, lambda: np.random.uniform(0, 1)),\n",
    "    \"lr_decay\": (float, lambda: 10 ** np.random.uniform(-6, 0)),\n",
    "    \"hidden_layers\": (int, lambda: np.round(np.random.uniform(0, 5))),\n",
    "    \"hidden_size\": (int, lambda: np.round(np.random.uniform(1, 25))),\n",
    "    \"activation\": (str, lambda: np.random.choice([\"linear\", \"sigmoid\", \"tanh\"]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T15:34:10.155683Z",
     "start_time": "2018-02-12T15:29:47.155Z"
    }
   },
   "source": [
    "### Configure the fitness function\n",
    "The fitness function is the most important here, because it is what **determines the score of an individual** and thus a generation. The more precise it is, the more you have control over how your individuals are chosen and the speed of the convergence towards a good generation. However the components must stay sufficiently \"free\" and simple to reveal the real power of random solution.  \n",
    "\n",
    "While the goal is to have a low fitness, we set **1000** as a default component evaluated value. The components of the fitness are the following:\n",
    "* The last **accuracy** (emphasized)\n",
    "* The last **train loss**\n",
    "* The last **test loss**\n",
    "* The **time** for an epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.576753Z",
     "start_time": "2018-03-01T12:20:44.505Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fitness_components(model) -> list:\n",
    "    \n",
    "    components = {\n",
    "        \"accuracy_emphasized\": 1000, \n",
    "        \"train_loss\": 1000, \n",
    "        \"validation_loss\": 1000, \n",
    "        \"mean_epoch_time\": 1000\n",
    "    }\n",
    "    \n",
    "    if len(model.train_losses) > 0 and len(model.metrics) > 0:\n",
    "        components[\"accuracy_emphasized\"] = np.sqrt(1-model.metrics[-1][\"accuracy\"]) * 10\n",
    "        components[\"train_loss\"] = model.train_losses[-1] \n",
    "        components[\"validation_loss\"] = model.validation_losses[-1] \n",
    "        components[\"mean_epoch_time\"] = np.mean(model.times) \n",
    "    \n",
    "    return components\n",
    "\n",
    "def calc_fitness(model):\n",
    "    \n",
    "    epochs = 300\n",
    "    model.fit(X_train, y_train, X_val, y_val, X_test, y_test, epochs=epochs, early_stopping=True)   \n",
    "    fitness = 0\n",
    "    for value in get_fitness_components(model).values(): # add up all components  \n",
    "        fitness += value\n",
    "    \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is the most important component, this is why we set it as emphasized. Also, the goal is to make a distinction between a 0.97 and 0.98 of accuracy. Here's how we do, using the **squared root**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.580262Z",
     "start_time": "2018-03-01T12:20:44.514Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracies = np.arange(0, 1, 0.001)\n",
    "emphasized = np.sqrt(1-accuracies)*10\n",
    "\n",
    "plt.plot(accuracies, 1-accuracies, label=\"linear 1-accuracy\")\n",
    "plt.plot(accuracies, emphasized, label=\"sqrt 1-accuracy x10\")\n",
    "plt.xlabel(\"Accuracies\")\n",
    "plt.ylabel(\"Fitness impact\")\n",
    "plt.legend()\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can analyze how much each component of the fitness function was prominent. Taking **m1**, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.582769Z",
     "start_time": "2018-03-01T12:20:44.520Z"
    }
   },
   "outputs": [],
   "source": [
    "m1_fitness = calc_fitness(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.585276Z",
     "start_time": "2018-03-01T12:20:44.527Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_fitness_components(model):\n",
    "    components = get_fitness_components(model)\n",
    "    for name in components.keys():\n",
    "        components[name] = [components[name], m1_fitness, \"{:.1%}\".format(components[name] / m1_fitness)]\n",
    "    \n",
    "    return pd.DataFrame(components, index=[\"value\", \"fitness\", \"percentage\"])\n",
    "\n",
    "analyze_fitness_components(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T17:47:00.438698Z",
     "start_time": "2018-02-12T17:47:00.407362Z"
    }
   },
   "source": [
    "### Define the callback function\n",
    "This is an optional function that will be called after each evolution, mostly for display-purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.587281Z",
     "start_time": "2018-03-01T12:20:44.534Z"
    }
   },
   "outputs": [],
   "source": [
    "def callback():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,4))\n",
    "    for p in ev.population:\n",
    "        print(p)\n",
    "        ax1.plot(p.obj.train_losses)\n",
    "        ax2.plot(p.obj.validation_losses)\n",
    "    ax1.set_title(\"Training losses\")\n",
    "    ax2.set_title(\"Validation losses\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch the genetic evolution \n",
    "Here's the command to reload the core module without reloading the whole notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.589286Z",
     "start_time": "2018-03-01T12:20:44.541Z"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(genev)\n",
    "\n",
    "import genev\n",
    "from genev import Evolution, Individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the initial population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.592295Z",
     "start_time": "2018-03-01T12:20:44.560Z"
    }
   },
   "outputs": [],
   "source": [
    "ev = Evolution(10, structure=Model, dna_skeleton=skeleton)\n",
    "ev.model(Model, skeleton, calc_fitness)\n",
    "ev.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.594299Z",
     "start_time": "2018-03-01T12:20:44.567Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ev.evaluate(display=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.596806Z",
     "start_time": "2018-03-01T12:20:44.573Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callback();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T15:35:23.906180Z",
     "start_time": "2018-02-12T15:34:47.408Z"
    }
   },
   "source": [
    "### Evolve the population\n",
    "Evolving the population can take some time. Here are some stats for training on **10% of the whole dataset**:   \n",
    "\n",
    "For 300 epochs each and 10 individuals over 10 generations, it took like ~9min (`early_stopping=False`).   \n",
    "For 300 epochs each and 15 individuals over 10 generations, it took like ~11min (`early_stopping=False`).   \n",
    "For 300 epochs each and 15 individuals over 10 generations, it took like ~7min (`early_stopping=True`).   \n",
    "For 300 epochs each and 15 individuals over 20 generations, it took like ~24min (`early_stopping=True`).   \n",
    "\n",
    "> On a **dedicated server** (8 cores instead of 4):   \n",
    "> For 300 epochs each and 15 individuals over 30 generations, it took like ~22min (`early_stopping=True`).   \n",
    "> The result was not better.   \n",
    "\n",
    "A few ideas in order to improve the time of the generations:\n",
    "* Start with an estimation of a good generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.598311Z",
     "start_time": "2018-03-01T12:20:44.580Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ev.evolve(10, callback)\n",
    "ev.evaluate(display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T15:35:23.907684Z",
     "start_time": "2018-02-12T15:35:14.515Z"
    }
   },
   "source": [
    "### Display the best player in the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.602322Z",
     "start_time": "2018-03-01T12:20:44.588Z"
    }
   },
   "outputs": [],
   "source": [
    "elite = ev.elite\n",
    "elite.obj.display_losses()\n",
    "elite.obj.display_metrics()\n",
    "plt.show()\n",
    "\n",
    "print(elite)\n",
    "print(\"\\t\\ttrain_loss\", elite.obj.train_losses[-1])\n",
    "print(\"\\t\\tvalidation_loss\", elite.obj.validation_losses[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-14T11:59:29.902147Z",
     "start_time": "2018-02-14T11:59:29.886496Z"
    }
   },
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.605329Z",
     "start_time": "2018-03-01T12:20:44.598Z"
    }
   },
   "outputs": [],
   "source": [
    "elite.dna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy and get the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.608838Z",
     "start_time": "2018-03-01T12:20:44.605Z"
    }
   },
   "outputs": [],
   "source": [
    "elite.obj.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitness score composition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.612347Z",
     "start_time": "2018-03-01T12:20:44.614Z"
    }
   },
   "outputs": [],
   "source": [
    "analyze_fitness_components(elite.obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T15:39:38.761106Z",
     "start_time": "2018-02-12T15:37:42.171Z"
    }
   },
   "source": [
    "### Analyze how parameters influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.615857Z",
     "start_time": "2018-03-01T12:20:44.620Z"
    }
   },
   "outputs": [],
   "source": [
    "list(ev.skeleton_stats.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visual analysis will help us to understand which values were generated and how they are collerated to the success of the fitness score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-01T12:22:14.617861Z",
     "start_time": "2018-03-01T12:20:44.629Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ev.visual_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-26T15:01:36.823626Z",
     "start_time": "2018-02-26T15:01:36.807968Z"
    }
   },
   "source": [
    "# Conclusion\n",
    "Le genetic algorithm ne converge pas vers la bonne solution. Il reste à chaque fois dans un local optimum, que cela soit sur 10 ou 40 epochs. Il y a deux problèmes:\n",
    "* Soit on permet à l'élite de muter, mais on peut le perdre. Finalement, le GA tourne en boucle sans jamais converger, changeant d'élite tout le temps.\n",
    "* Soit on fixe l'élite. L'élite ne change pas, on reste bloqué. Finalement seul le tirage aléatoire du début influe. C'est à se demander si le crossover fonctionne vraiment ??\n",
    "\n",
    "Ou alors il n'est juste pas possible de descendre plus bas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "291px",
    "width": "265px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "221px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
